{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1"
      ],
      "metadata": {
        "id": "wq5ox1isOjQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### part a"
      ],
      "metadata": {
        "id": "Cg57fvipOuU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "kFWr6eI04a4H"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "    # Define the function you want to optimize\n",
        "    return x[0]**2 + x[1]**2\n",
        "\n",
        "def gradient_f(x):\n",
        "    # Compute the gradient of the function at point x\n",
        "    return np.array([2 * x[0], 2 * x[1]])\n",
        "\n",
        "def gradient_descent(initial_x, learning_rate, num_iterations):\n",
        "    x = initial_x\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        gradient = gradient_f(x)\n",
        "        x = x - learning_rate * gradient\n",
        "\n",
        "    return x\n",
        "\n",
        "# Set the initial point and learning rate\n",
        "initial_point = np.array([1.0, 1.0])\n",
        "learning_rate = 0.1\n",
        "num_iterations = 100\n",
        "\n",
        "# Run gradient descent\n",
        "optimized_point = gradient_descent(initial_point, learning_rate, num_iterations)\n",
        "\n",
        "print(\"Optimized point:\", optimized_point)\n",
        "print(\"Optimized function value:\", f(optimized_point))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP4KFTzjVI-2",
        "outputId": "13628951-fad9-42b0-8ba0-3c5501784495"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized point: [2.03703598e-10 2.03703598e-10]\n",
            "Optimized function value: 8.299031137761999e-20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### idea for pseudocode??\n",
        "\n",
        "# input any function\n",
        "    # create np array of x_in = [-100, -99, ... , 0, ... , 99, 100]\n",
        "    # create np array of y_in the same\n",
        "    # f = the function to descend gradiently using x_in and y_in\n",
        "        # this will give us an np array with all the function outputs?\n",
        "# gradient = numpy.gradient(f)"
      ],
      "metadata": {
        "id": "07eFErgpYNEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 50\n",
        "m = 100\n",
        "t0, t1 = 5, 50 # learning schedule hyperparameters\n",
        "\n",
        "def learning_schedule(t):\n",
        "    return t0 / (t+t1)\n",
        "\n",
        "theta = np.random.randn(2,1) # random initialization\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i in range(m):\n",
        "            random_index = np.random.randint(m)\n",
        "            xi = X_b[random_index : random_index+1]\n",
        "            yi = y[random_index : random_index+1]\n",
        "            gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
        "            eta = learning_schedule(epoch * m + i)\n",
        "            theta = theta - eta * gradients\n",
        "\n",
        "print(theta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "JSKrdErbOlYh",
        "outputId": "49d42c44-9e11-4bed-e857-4902a5cc36e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a3272e0d5cf6>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mrandom_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mxi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_index\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mrandom_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0myi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_index\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mrandom_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_b' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2"
      ],
      "metadata": {
        "id": "I6gWOaDD484i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ShEL7MVvJw4",
        "outputId": "9ff3269d-98e4-4c20-bdba-9aef287bf97d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "mnist.keys()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = mnist[\"data\"], mnist[\"target\"]\n",
        "\n",
        "\n",
        "X = np.array(X)\n",
        "# print(X_np[0])\n",
        "\n",
        "# print(X)\n",
        "X.shape\n",
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuRu3Ey60kSb",
        "outputId": "090bb44d-2fef-42f3-ffd0-3f1550166cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "some_digit = X[0]\n",
        "some_digit_image = some_digit.reshape(28,28)\n",
        "\n",
        "plt.imshow(some_digit_image, cmap = mpl.cm.binary, interpolation=\"nearest\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "YCfHIAXm0yIU",
        "outputId": "336b938b-45b5-4704-c2f0-cdca2cf0d140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y[0])\n",
        "y = y.astype(np.uint8)\n",
        "# print(type(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftiWeZHm1mbG",
        "outputId": "99ee6f58-3770-4ae1-bc54-dfd86b23e0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
        "# print(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "ljOmc-am4dXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binary Classifier"
      ],
      "metadata": {
        "id": "owbwC2To_kSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_5 = (y_train == 5)\n",
        "y_test_5 = (y_test == 5)"
      ],
      "metadata": {
        "id": "xyHsXVDQ-VI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd_clf = SGDClassifier(random_state=42)\n",
        "sgd_clf.fit(X_train, y_train_5)\n",
        "\n",
        "sgd_clf.predict([some_digit])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5NacoK5-bgn",
        "outputId": "47a7cf3a-b8e7-460b-8349-c773ec12b05c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross Validation"
      ],
      "metadata": {
        "id": "DpIgZqJc_glc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.base import clone\n",
        "\n",
        "skfolds = StratifiedKFold(n_splits=5)\n",
        "\n",
        "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
        "    clone_clf = clone(sgd_clf)\n",
        "    X_train_folds = X_train[train_index]\n",
        "    y_train_folds = y_train_5[train_index]\n",
        "    X_test_fold = X_train[test_index]\n",
        "    y_test_fold = y_train_5[test_index]\n",
        "\n",
        "    clone_clf.fit(X_train_folds, y_train_folds)\n",
        "    y_pred = clone_clf.predict(X_test_fold)\n",
        "    n_correct = sum(y_pred == y_test_fold)\n",
        "    print(n_correct / len(y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKZA_ip7_o4Q",
        "outputId": "8237a1aa-ef3b-4b35-d196-5dc3de738031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9546666666666667\n",
            "0.96975\n",
            "0.9635\n",
            "0.9653333333333334\n",
            "0.9484166666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "cross_val_score(sgd_clf, X_train, y_train_5, cv=5, scoring=\"accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biRxc917BCOa",
        "outputId": "d881d03f-5c92-4395-e787-1663a85b386f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.95466667, 0.96975   , 0.9635    , 0.96533333, 0.94841667])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. OvA\n",
        "2. Random Forest\n",
        "3. KNeighbors (probably will work best)"
      ],
      "metadata": {
        "id": "D1p_oIuyDvqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ],
      "metadata": {
        "id": "Kp4MoHq_I415"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "OEa9GZ7UI7TK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OvA"
      ],
      "metadata": {
        "id": "YMeXfs--EaVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_clf.fit(X_train, y_train)\n",
        "sgd_clf.predict([some_digit])\n",
        "\n",
        "some_digit_scores = sgd_clf.decision_function([some_digit])\n",
        "\n",
        "y_train_ova_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=5)\n",
        "f1_score(y_train, y_train_ova_pred, average=\"macro\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oODiwTYjEmS1",
        "outputId": "8548a52d-5d4e-4bcc-e800-0b4333620834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8780295041097735"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OvA is slower, literally took 16 minutes for .87 f1"
      ],
      "metadata": {
        "id": "yZCrR7b6T-TC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "4tWE_A_FEb1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "forest_clf = RandomForestClassifier(random_state=42)\n",
        "forest_clf.fit(X_train, y_train)\n",
        "forest_clf.predict([some_digit])\n",
        "\n",
        "forest_clf.predict_proba([some_digit])\n",
        "\n",
        "y_train_forest_pred = cross_val_predict(forest_clf, X_train, y_train, cv=5)\n",
        "f1_score(y_train, y_train_forest_pred, average=\"macro\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ut8t8qAJE8W5",
        "outputId": "bf3f88e4-bb59-461a-9cd7-05d95ae1e1d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9661919580821857"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is ok, but not a lot of room for hyperparams (or at least to the same extent as k neighbors)"
      ],
      "metadata": {
        "id": "QWERnAJAUFWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K Neighbors"
      ],
      "metadata": {
        "id": "iMqh5EUyEdhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "y_train_large = (y_train >= 7)\n",
        "y_train_odd = (y_train % 2 == 1)\n",
        "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
        "\n",
        "knn_clf = KNeighborsClassifier()\n",
        "knn_clf.fit(X_train, y_multilabel)\n",
        "\n",
        "knn_clf.predict([some_digit])\n",
        "\n",
        "\n",
        "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=5)\n",
        "f1_score(y_multilabel, y_train_knn_pred, average=\"macro\")\n",
        "\n",
        "\n",
        "\n",
        "### TEST\n",
        "\n",
        "y_test_large = (y_test >= 7)\n",
        "y_test_odd = (y_test % 2 == 1)\n",
        "y_multilabel_test = np.c_[y_test_large, y_test_odd]\n",
        "\n",
        "y_test_knn_pred = cross_val_predict(knn_clf, X_test, y_multilabel_test, cv=5)\n",
        "f1_score(y_multilabel_test, y_test_knn_pred, average=\"macro\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4MS5NqJEfU9",
        "outputId": "fd1b0465-e2fe-4c5a-ecf8-79bcd897ea7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9625164092416195"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN is probably best because fastest and close with forest, hyperparams could probably help KNN better than forest"
      ],
      "metadata": {
        "id": "jiM93wiGRFTN"
      }
    }
  ]
}